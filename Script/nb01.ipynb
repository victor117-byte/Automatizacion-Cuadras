{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Declaracion:  74\n",
      "Files Opinion Cumplimineto:  11\n",
      "Files Acuse Presentacion:  0\n",
      "Files Constancia:  13\n",
      "Files Diot:  12\n",
      "Files Pagos:  78\n",
      "Files Sin Clasificacion:  0\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# root = r\"C:\\Users\\Victor\\Documents\\Cursos\\Python\\Automatizacion\\PDF\"\n",
    "root = r\"../../PDF/\"\n",
    "path = os.path.join(root, \"../../PDF/\")\n",
    "\n",
    "# Funcion que obtiene los archivos con su ruta y se encarga de clasificarlos en arreglos\n",
    "def ArchivosPDF(root, path):\n",
    "    Archivos_Acuse_Recepcion = []\n",
    "    Archivos_Opinion_Cumplimiento = []\n",
    "    Archivos_Acuse_Presentacion = []\n",
    "    Archivos_Constancia = []\n",
    "    Archivos_Diot = []\n",
    "    Archivos_Pago = []\n",
    "    Archivos_no_clasificados = []\n",
    "    \n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            # print(os.path.join(path, name))\n",
    "            if os.path.join(name).endswith(\".pdf\"):\n",
    "                #Archivos Acuse Recepcion\n",
    "                # print(os.path.join(name))\n",
    "                if os.path.join(name).upper().startswith(\"DECLARACION\"):\n",
    "                    Archivos_Acuse_Recepcion.append(os.path.join(path, name))\n",
    "                elif os.path.join(name).upper().startswith(\"OPINION\"):\n",
    "                    Archivos_Opinion_Cumplimiento.append(os.path.join(path, name))\n",
    "                elif os.path.join(name).startswith(\"acuse presentacion\"):\n",
    "                    Archivos_Acuse_Presentacion.append(os.path.join(path, name))\n",
    "                elif os.path.join(name).upper().startswith(\"CONSTANCIA\"):\n",
    "                    Archivos_Constancia.append(os.path.join(path, name))\n",
    "                elif os.path.join(name).upper().startswith(\"DIOT\"):\n",
    "                    Archivos_Diot.append(os.path.join(path, name))\n",
    "                elif os.path.join(name).upper().startswith(\"PAGO\"):\n",
    "                    Archivos_Pago.append(os.path.join(path, name))\n",
    "                else: \n",
    "                    Archivos_no_clasificados.append(os.path.join(path, name))\n",
    "                    \n",
    "    return Archivos_Acuse_Recepcion, Archivos_Opinion_Cumplimiento, Archivos_Acuse_Presentacion, Archivos_Constancia, Archivos_Diot, Archivos_Pago, Archivos_no_clasificados\n",
    "\n",
    "\n",
    "# -> Papelines de Extraccion \n",
    "\n",
    "# Varibales de PDF's'\n",
    "# Se asigna el tipo de pdf a un variable\n",
    "\n",
    "Archivos_Declaracion = (ArchivosPDF(root, path)[0])         #--> Solo contiene 1 archivo\n",
    "Archivos_Opinion_Cumplimiento = (ArchivosPDF(root, path)[1])    #--> Solo contiene 1 archivo\n",
    "Archivos_Acuse_Presentacion = (ArchivosPDF(root, path)[2])      #--> °Contiene archivos Dummies y 1 original para pruebas\n",
    "Archivos_Constancia = (ArchivosPDF(root, path)[3])              #--> Solo contiene 1 archivo\n",
    "Archivos_Diot = (ArchivosPDF(root, path)[4])                    #--> Solo contiene 1 archivo\n",
    "Archivos_Pagos = (ArchivosPDF(root, path)[5])         #--> Solo contiene 1 archivo\n",
    "Archivos_no_clasificados = (ArchivosPDF(root, path)[6])         #--> Solo contiene 1 archivo\n",
    "\n",
    "\n",
    "print(\"Files Declaracion: \", len(Archivos_Declaracion))\n",
    "print(\"Files Opinion Cumplimineto: \",len(Archivos_Opinion_Cumplimiento))\n",
    "print(\"Files Acuse Presentacion: \",len(Archivos_Acuse_Presentacion))\n",
    "print(\"Files Constancia: \",len(Archivos_Constancia))\n",
    "print(\"Files Diot: \",len(Archivos_Diot))\n",
    "print(\"Files Pagos: \",len(Archivos_Pagos))\n",
    "print(\"Files Sin Clasificacion: \",len(Archivos_no_clasificados))\n",
    "\n",
    "\n",
    "# Principal Functions Text Mining by PDF types\n",
    "# -> Each function returns a numpy array with the result found but, if not found, defaults to NA\n",
    "# -> Each function uses \"txt\" value containing all the text by per PDF iteration\n",
    "# -> Each function should return the headers so, that they are recognized on the first line by Pandas\n",
    "\n",
    "\n",
    "def exportDataDeclaracion(Archivos):\n",
    "    array_docs = []\n",
    "    for i in range(len(Archivos)):\n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(txt)  # Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "\n",
    "        # rfc\n",
    "        rfc = re.search(\"RFC:.(.*?\\s)\", txt).group(1)\n",
    "        # Fecha\n",
    "        try:\n",
    "            Fecha_y_hora_presentacion = re.search(\n",
    "                \"Fecha y hora de presentaci.n:.{11}\", txt)[0]\n",
    "            Fecha_y_hora_presentacion = re.split(':', Fecha_y_hora_presentacion)[1]\n",
    "        except:\n",
    "            Fecha_y_hora_presentacion = \"NA\"\n",
    "\n",
    "        # numero de operacion\n",
    "        try:\n",
    "            Num_de_Operacion = re.search(\n",
    "                \"N.mero de operaci.n:.(\\d*?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Num_de_Operacion = \"NA\"\n",
    "        # periodo de la declaracion\n",
    "        try:\n",
    "            Periodo_de_declaracion = re.search(\n",
    "                \"Per.odo de la declaraci.n:\\s(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Periodo_de_declaracion = \"NA\"\n",
    "        # Ejercicio\n",
    "        try:\n",
    "            Ejercicio = re.search(\"Ejercicio:\\s(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Ejercicio = \"NA\"\n",
    "        # Denominación o razón social:\n",
    "\n",
    "        try:\n",
    "            RazonSocial = re.search(\"Hoja\\d\\sde\\s\\d.(.*?)Tipo\", txt).group(1)\n",
    "        except:\n",
    "            RazonSocial = 'NA'\n",
    "\n",
    "        # SELECCION LINEA DE CAPTURA\n",
    "        try:\n",
    "            total_a_pagar = re.search(\"total a pagar:(.+?\\s)\", txt).group(1)\n",
    "            Vigente_hasta = re.search(\"Vigente hasta:(.+?\\s)\", txt).group(1)\n",
    "            Linea_de_Captura = \"Linea de Captura : \" + \\\n",
    "                re.search(\"Línea de Captura:.(.*?)Importe\", txt).group(1)\n",
    "        except:\n",
    "            total_a_pagar = \"NA\"\n",
    "            Vigente_hasta = \"NA\"\n",
    "            Linea_de_Captura = \"NA \"\n",
    "        # SALDO A FAVOR\n",
    "        try:\n",
    "            Impuesto_a_favor = re.search(\n",
    "                \"Impuesto.a.favor:.(.*?)ACUSE\", txt).group(1)\n",
    "            Impuesto_a_favor = re.split(' ', Impuesto_a_favor)[0]\n",
    "            # print(Impuesto_a_favor)\n",
    "        except:\n",
    "            Impuesto_a_favor = 'NA'\n",
    "\n",
    "        # data_fila = [rfc, Fecha_y_hora_presentacion, Num_de_Operacion, Periodo_de_declaracion, Ejercicio,  total_a_pagar, Vigente_hasta, Linea_de_Captura, Archivos[i]]\n",
    "        # print(txt)\n",
    "        arreglo_conceptos = funcion_Conceptos(txt)\n",
    "        # print(f\">>>{arreglo_conceptos}\")\n",
    "            \n",
    "        for w in range(len(arreglo_conceptos)):\n",
    "            # print(\"----datos ----\")\n",
    "            # print(arreglo_conceptos[w])\n",
    "            data_fila = np.array([\n",
    "                \"Declaracion\",\n",
    "                rfc,\n",
    "                Fecha_y_hora_presentacion,\n",
    "                Num_de_Operacion,\n",
    "                Periodo_de_declaracion,\n",
    "                Ejercicio,\n",
    "                total_a_pagar,\n",
    "                Vigente_hasta,\n",
    "                Linea_de_Captura,\n",
    "                RazonSocial,\n",
    "                Impuesto_a_favor,\n",
    "                arreglo_conceptos[w],\n",
    "                Archivos[i]\n",
    "                ])\n",
    "            # print(data_fila)\n",
    "            array_docs.append(data_fila)\n",
    "        \n",
    "        # print(array_rows)\n",
    "        \n",
    "        # array_docs.append(data_fila)\n",
    "    return array_docs\n",
    "\n",
    "    #     data_fila = np.array([\n",
    "    #         \"Declaracion\",\n",
    "    #         rfc,\n",
    "    #         Fecha_y_hora_presentacion,\n",
    "    #         Num_de_Operacion,\n",
    "    #         Periodo_de_declaracion,\n",
    "    #         Ejercicio,\n",
    "    #         total_a_pagar,\n",
    "    #         Vigente_hasta,\n",
    "    #         Linea_de_Captura,\n",
    "    #         RazonSocial,\n",
    "    #         Impuesto_a_favor,\n",
    "    #         Archivos[i]])\n",
    "    #     array_docs.append(data_fila)\n",
    "\n",
    "    # return array_docs\n",
    "\n",
    "def exportDataAcuseRecepcion(Archivos):\n",
    "    array_docs = []\n",
    "    for i in range(len(Archivos)):\n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(txt)  # Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "\n",
    "        # rfc\n",
    "        rfc = re.search(\"RFC:.(.*?\\s)\", txt).group(1)\n",
    "        # Fecha\n",
    "        try:\n",
    "            Fecha_y_hora_presentacion = re.search(\n",
    "                \"Fecha y hora de presentaci.n:.{11}\", txt)[0]\n",
    "            Fecha_y_hora_presentacion = re.split(':', Fecha_y_hora_presentacion)[1]\n",
    "        except:\n",
    "            Fecha_y_hora_presentacion = \"NA\"\n",
    "\n",
    "        # numero de operacion\n",
    "        try:\n",
    "            Num_de_Operacion = re.search(\n",
    "                \"N.mero de operaci.n:.(\\d*?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Num_de_Operacion = \"NA\"\n",
    "        # periodo de la declaracion\n",
    "        try:\n",
    "            Periodo_de_declaracion = re.search(\n",
    "                \"Per.odo de la declaraci.n:\\s(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Periodo_de_declaracion = \"NA\"\n",
    "        # Ejercicio\n",
    "        try:\n",
    "            Ejercicio = re.search(\"Ejercicio:\\s(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Ejercicio = \"NA\"\n",
    "        # Denominación o razón social:\n",
    "\n",
    "        try:\n",
    "            RazonSocial = re.search(\"Hoja\\d\\sde\\s\\d.(.*?)Tipo\", txt).group(1)\n",
    "        except:\n",
    "            RazonSocial = 'NA'\n",
    "\n",
    "        # SELECCION LINEA DE CAPTURA\n",
    "        try:\n",
    "            total_a_pagar = re.search(\"total a pagar:(.+?\\s)\", txt).group(1)\n",
    "            Vigente_hasta = re.search(\"Vigente hasta:(.+?\\s)\", txt).group(1)\n",
    "            Linea_de_Captura = \"Linea de Captura : \" + \\\n",
    "                re.search(\"L.nea de Captura:(.*?)Importe\", txt).group(1)\n",
    "        except:\n",
    "            total_a_pagar = \"NA\"\n",
    "            Vigente_hasta = \"NA\"\n",
    "            Linea_de_Captura = \"NA \"\n",
    "        # SALDO A FAVOR\n",
    "        try:\n",
    "            Impuesto_a_favor = re.search(\n",
    "                \"Impuesto.a.favor:.(.*?)ACUSE\", txt).group(1)\n",
    "            Impuesto_a_favor = re.split(' ', Impuesto_a_favor)[0]\n",
    "            # print(Impuesto_a_favor)\n",
    "        except:\n",
    "            Impuesto_a_favor = 'NA'\n",
    "\n",
    "        # data_fila = [rfc, Fecha_y_hora_presentacion, Num_de_Operacion, Periodo_de_declaracion, Ejercicio,  total_a_pagar, Vigente_hasta, Linea_de_Captura, Archivos[i]]\n",
    "        \n",
    "\n",
    "        data_fila = np.array([\n",
    "            \"Acuse Recepcion\",\n",
    "            rfc,\n",
    "            Fecha_y_hora_presentacion,\n",
    "            Num_de_Operacion,\n",
    "            Periodo_de_declaracion,\n",
    "            Ejercicio,\n",
    "            total_a_pagar,\n",
    "            Vigente_hasta,\n",
    "            Linea_de_Captura,\n",
    "            RazonSocial,\n",
    "            Impuesto_a_favor,\n",
    "            Archivos[i]])\n",
    "        array_docs.append(data_fila)\n",
    "\n",
    "    return array_docs\n",
    "\n",
    "def exportDataDiot(Archivos):\n",
    "    array_docs = []\n",
    "    for i in range(len(Archivos)):\n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(txt) #Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "\n",
    "        # Usuario\n",
    "        try:\n",
    "            usuario = re.search(\"Usuario:.(.+?\\s)\", txt)[0]\n",
    "            usuario = re.split(':', usuario)[1]\n",
    "        except:\n",
    "            usuario = \"NA\"\n",
    "\n",
    "        # Archivo\n",
    "        try:\n",
    "            Archivo_Recibido = re.search(\"Archivo Recibido:.(.+?\\s)\", txt)[0]\n",
    "            Archivo_Recibido = re.split(\":_\", Archivo_Recibido)[1]\n",
    "        except:\n",
    "            Archivo_Recibido = \"NA\"\n",
    "\n",
    "        # Tamanio\n",
    "        try:\n",
    "            tamanio = re.search(\"Tama.o:.(.+?\\s)\", txt)[0]\n",
    "        except:\n",
    "            tamanio = \"NA\"\n",
    "        # Fecha de recepcion\n",
    "        try:\n",
    "            Fecha_Recepcion = re.search(\"Fecha de Recepci.n:.(.+?\\s)\", txt)[0]\n",
    "            Fecha_Recepcion = re.split(':', Fecha_Recepcion)[1]\n",
    "        except:\n",
    "            Fecha_Recepcion = \"NA\"\n",
    "        # Hora de recepcion\n",
    "        try:\n",
    "            Hora_Recepcion = re.search(\"Hora de Recepci.n:.(.+?\\s)\", txt)[0]\n",
    "            Hora_Recepcion = re.split('Recepci.n:', Hora_Recepcion)[1]\n",
    "        except:\n",
    "            Hora_Recepcion = \"NA\"\n",
    "        # Folio\n",
    "        try:\n",
    "            Folio = re.search(\"Folio de Recepci.n:.(.+?\\s)\", txt)[0]\n",
    "            Folio = re.split(':', Folio)[1]\n",
    "        except:\n",
    "            Folio = \"NA\"\n",
    "\n",
    "        \n",
    "\n",
    "        data_fila = np.array([\n",
    "            \"Diot\",\n",
    "            usuario,\n",
    "            Archivo_Recibido,\n",
    "            tamanio,\n",
    "            Fecha_Recepcion,\n",
    "            Hora_Recepcion,\n",
    "            Folio,\n",
    "            Archivos[i]\n",
    "        ])\n",
    "        array_docs.append(data_fila)\n",
    "\n",
    "    return array_docs\n",
    "\n",
    "def exportDataConstancia(Archivos):\n",
    "    array_docs = []\n",
    "    for i in range(len(Archivos)):\n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(txt)  # Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "\n",
    "        # RFC\n",
    "        try:\n",
    "            rfc = re.search(\"RFC:.(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            rfc = \"NA\"\n",
    "        # RazonSocial/CURP\n",
    "        try:\n",
    "            Razon_Social_Nombre = re.search(\n",
    "                \".Social:.(.+?\\s)R.gimen\", txt)[0][:-8]\n",
    "            Razon_Social_Nombre = re.split(':', Razon_Social_Nombre)[1]\n",
    "        except:\n",
    "            try:\n",
    "                Razon_Social_Nombre = re.search(\".CURP:.(.+?\\s)\", txt)[0]\n",
    "                Razon_Social_Nombre = re.split(':', Razon_Social_Nombre)[1]\n",
    "            except:\n",
    "                Razon_Social_Nombre = \"NA\"\n",
    "\n",
    "        # REGIMEN CAPITAL O NOMBRE\n",
    "        try:\n",
    "            Regimen_Nombre = re.search(\".CURP:.(.+?\\s)\", txt)[0]\n",
    "            Regimen_Nombre = re.split(':', Regimen_Nombre)[1]\n",
    "        except:\n",
    "            try:\n",
    "                Regimen_Nombre = re.search(\".CURP:.(.+?\\s)\", txt)[0]\n",
    "            except:\n",
    "                Regimen_Nombre = \"NA\"\n",
    "        # PRIMER APELLIDO\n",
    "        try:\n",
    "            Primer_Apellido = re.search(\"PrimerApellido:(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Primer_Apellido = 'NA'\n",
    "        # SEGUNDO APELLIDO\n",
    "        try:\n",
    "            Segundo_Apellido = re.search(\"Segundo.Apellido:(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Segundo_Apellido = 'NA'\n",
    "        # NOMBRE COMERICAL\n",
    "        try:\n",
    "            Nombre_Comercial = re.search(\n",
    "                \"NombreComercial:(.+?\\s)Fecha.\", txt).group(1)[1:]\n",
    "            if Nombre_Comercial.startswith('Fecha') or Nombre_Comercial.startswith('Datos del domicilio'):\n",
    "                Nombre_Comercial = 'NA'\n",
    "            if re.findall('Datos.', Nombre_Comercial):\n",
    "                Nombre_Comercial = re.split('Datos.', Nombre_Comercial)[0]\n",
    "\n",
    "        except:\n",
    "            Nombre_Comercial = 'NA'\n",
    "        # FECHA OPERACIONES\n",
    "        try:\n",
    "            Fecha_Operaciones = re.search(\n",
    "                \"Fechainiciodeoperaciones:(.+?\\s)Estatus\", txt).group(1)[:-1]\n",
    "        except:\n",
    "            Fecha_Operaciones = 'NA'\n",
    "        # ESTATUS\n",
    "        try:\n",
    "            Estatus = re.search(\"Estatusenelpadr.n:(.+?\\s)\", txt).group(1)\n",
    "        except:\n",
    "            Estatus = 'NA'\n",
    "        # REGIMENES\n",
    "        try:\n",
    "            Regimenes = re.search(\"Reg.menes:(.+?\\s)Obligaciones\", txt)[0]\n",
    "\n",
    "        except:\n",
    "            Regimenes = 'NA'\n",
    "\n",
    "        \n",
    "\n",
    "        data_fila = np.array([\n",
    "            \"Constancia\",\n",
    "            rfc,\n",
    "            Razon_Social_Nombre,\n",
    "            Regimen_Nombre,\n",
    "            Primer_Apellido,\n",
    "            Segundo_Apellido,\n",
    "            Nombre_Comercial,\n",
    "            Fecha_Operaciones,\n",
    "            Estatus,\n",
    "            Regimenes,\n",
    "            Archivos[i]\n",
    "        ])\n",
    "        array_docs.append(data_fila)\n",
    "        \n",
    "\n",
    "    return array_docs\n",
    "\n",
    "def exportDataOpinionCumplimiento(Archivos):\n",
    "    array_docs = []\n",
    "    for i in range(len(Archivos)):\n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(txt)  # Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "\n",
    "        # Folio\n",
    "        try:\n",
    "            folio = re.search('Folio.(.+?\\s)(.+?\\s)Respuesta', txt).group(2)\n",
    "            # print(f'Folio: {folio} Tiene una longitud de: ', len(folio))\n",
    "        except:\n",
    "            folio = 'NA'\n",
    "        # Clave RFC\n",
    "        try:\n",
    "            RFC = re.search('Folio.(.+?\\s)(.+?\\s)Respuesta', txt).group(1)\n",
    "            # print(f'RFC: {RFC} Tiene una longitud de: ', len(RFC))\n",
    "        except:\n",
    "            RFC = 'NA'\n",
    "\n",
    "        data_fila = np.array([\n",
    "            'Opinion cumplimiento',\n",
    "            RFC,\n",
    "            folio,\n",
    "            Archivos[i]\n",
    "        ])\n",
    "        array_docs.append(data_fila)\n",
    "\n",
    "    return array_docs\n",
    "\n",
    "def exportDataPagos(Archivos):\n",
    "    array_docs = []\n",
    "    array_rows = []\n",
    "    for i in range(len(Archivos)):\n",
    "    \n",
    "\n",
    "        pdf = open(Archivos[i], 'rb')\n",
    "        # print(Archivos[i])\n",
    "        reader = PyPDF2.PdfReader(pdf)\n",
    "        page = reader.pages\n",
    "        texto = ''\n",
    "\n",
    "        for pag in range(len(page)):\n",
    "            # print(\"pdf: \", i+1, \"pagina: \",pag+1)\n",
    "            # texto += reader._get_page(pag).extractText()\n",
    "            texto += reader._get_page(pag).extract_text()\n",
    "\n",
    "        # print(\"PDF: \", i+1)\n",
    "        txt = re.sub(\"\\n\", \" \", texto)\n",
    "        # print(f\">>>TEXTO {i}<<<\")\n",
    "        # print(f\"{txt}\")  # Muestra el texto en de todo el PDF\n",
    "\n",
    "        # Text Mining\n",
    "        # DATOS GENERALES\n",
    "        \n",
    "        # Get RFC\n",
    "        try:\n",
    "            rfc = re.search(\"RFC:(.+?\\s)\", txt).group(1)\n",
    "            rfc = rfc.strip()\n",
    "        except:\n",
    "            rfc = \"NA\"\n",
    "            \n",
    "        # Razon Social\n",
    "        try:\n",
    "            Entidad = re.search(\"raz.n.social:(.+?)Tipo\", txt).group(1)\n",
    "            Entidad = Entidad.strip()\n",
    "            Tipo = \"Persona Moral\"\n",
    "        except:\n",
    "            try:\n",
    "                Entidad = re.search(\"Nombre:(.+?)Tipo\", txt).group(1)\n",
    "                Entidad = Entidad.strip()\n",
    "                Tipo = \"Persona Fisica\"\n",
    "            except:\n",
    "                Entidad = \"NA\"\n",
    "                Tipo = \"NA\"\n",
    "                \n",
    "        # Fecha\n",
    "        try:\n",
    "            Fecha_presentacion = re.search(\"presentaci.n:(.+?\\s)\", txt).group(1)\n",
    "            Fecha_presentacion = Fecha_presentacion.strip()\n",
    "        except:\n",
    "            Fecha_presentacion = \"NA\"\n",
    "            \n",
    "        try:\n",
    "            Importe_a_pagar = re.search(\"total a pagar:(.+?) Vigente\", txt).group(1)\n",
    "        except:\n",
    "            Importe_a_pagar = \"NA\"\n",
    "            \n",
    "        try:\n",
    "            Linea_de_captura = re.search(\"Línea de Captura:(.+?)Importe\", txt).group(1)\n",
    "            Linea_de_captura = Linea_de_captura.strip()\n",
    "        except:\n",
    "            Linea_de_captura = \"NA\"\n",
    "        try:\n",
    "            Num_operacion = re.search(\"N.mero de operaci.n:(.+?)Sello\", txt).group(1)\n",
    "            Num_operacion = Num_operacion.strip()\n",
    "            try:\n",
    "                Num_operacion = Num_operacion.split(\"Fecha\")[0]\n",
    "            except:\n",
    "                Num_operacion = Num_operacion\n",
    "        except:\n",
    "            Num_operacion = \"NA\"\n",
    "            \n",
    "        # Fecha emision\n",
    "        try:\n",
    "            fecha_presentacion = re.search(\"hora de presentaci.n:.(.+?)Medio\", txt).group(1)\n",
    "            fecha_presentacion = fecha_presentacion.strip()\n",
    "        except:\n",
    "            fecha_presentacion = \"NA\"\n",
    "        # Tipo_declaracion \n",
    "        try:\n",
    "            Tipo_declaracion = re.search(\"Tipo.de.declaraci.n: (.+?)Tipo\", txt).group(1)\n",
    "            Tipo_declaracion = Tipo_declaracion.strip()\n",
    "            try:\n",
    "                Tipo_declaracion = Tipo_declaracion.split()[0]\n",
    "            except: \n",
    "                Tipo_declaracion = Tipo_declaracion\n",
    "        except:\n",
    "            Tipo_declaracion = \"NA\"\n",
    "        # Vigencia\n",
    "        try:\n",
    "            Vigencia = re.search(\"Vigente hasta: (.+?)Obligado\", txt).group(1)\n",
    "            Vigencia = Vigencia.strip()\n",
    "        except:\n",
    "            try:\n",
    "                Vigencia = re.search(\"Vigente hasta: (.+?)INFORMACI.N\", txt).group(1)\n",
    "                Vigencia = Vigencia.strip()\n",
    "            except:\n",
    "                Vigencia = \"NA\"\n",
    "        # # Periodo de declaracion\n",
    "        # try:\n",
    "        #     Periodo = re.search(\"Vigente hasta: (.+?)Obligado\", txt).group(1)\n",
    "        #     Periodo = Periodo.strip()\n",
    "        # except:\n",
    "            # Periodo = \"NA\"\n",
    "        # Fecha de Pago\n",
    "        try:\n",
    "            Fecha_de_pago = re.search(\"Fecha del pago:(.+?) L.nea\", txt).group(1)\n",
    "            Fecha_de_pago = Fecha_de_pago.strip()\n",
    "        except:\n",
    "            Fecha_de_pago = \"NA\"\n",
    "            \n",
    "        # Conceptos de pago\n",
    "        \n",
    "        arreglo_conceptos = funcion_Conceptos(txt)\n",
    "        # print(f\">>>{arreglo_conceptos}\")\n",
    "            \n",
    "        for w in range(len(arreglo_conceptos)):\n",
    "            # print(\"----datos ----\")\n",
    "            # print(arreglo_conceptos[w])\n",
    "            data_fila = np.array([\n",
    "                'Acuse Confirmacion de Pago',\n",
    "                rfc,\n",
    "                Entidad,\n",
    "                Tipo,\n",
    "                Fecha_presentacion,\n",
    "                Importe_a_pagar,\n",
    "                Linea_de_captura,\n",
    "                Num_operacion,\n",
    "                Vigencia,\n",
    "                Tipo_declaracion,\n",
    "                # Periodo,\n",
    "                Fecha_de_pago,\n",
    "                arreglo_conceptos[w],\n",
    "                Archivos[i]\n",
    "                ])\n",
    "            # print(data_fila)\n",
    "            array_docs.append(data_fila)\n",
    "        \n",
    "        # print(array_rows)\n",
    "        \n",
    "        # array_docs.append(data_fila)\n",
    "    return array_docs\n",
    "\n",
    "\n",
    "def funcion_Conceptos(txt):\n",
    "    Array_Conceptos = []\n",
    "    Conceptos = re.findall(\"Concepto de pago \\d:\", txt)\n",
    "    # print(f\"Cantidad-> {len(Conceptos)}\")\n",
    "    for i in range(6):\n",
    "        num = i+1\n",
    "        try: \n",
    "            _txt_concepto = \"Concepto.de.pago.\"+str(num)+\":(.+?)A cargo\" #Concepto de pago.1:(.+?) Impuesto\n",
    "            _Concepto = re.search(_txt_concepto, txt).group(1)\n",
    "            _Concepto = _Concepto.strip()\n",
    "        except:\n",
    "            try:\n",
    "                _txt_concepto = \"Concepto.de.pago.\"+str(num)+\":(.+?).Imp\" #Concepto de pago.1:(.+?) A cargo\n",
    "                _Concepto = re.search(_txt_concepto, txt).group(1)\n",
    "                _Concepto = _Concepto.strip()\n",
    "            except:\n",
    "                _Concepto = \"\"\n",
    "                \n",
    "        \n",
    "        if len(_Concepto) > 1:\n",
    "            Array_Conceptos.append(_Concepto)\n",
    "        \n",
    "    return Array_Conceptos\n",
    "        # print(f\"->{Array_Conceptos}\")\n",
    "\n",
    "\n",
    "# PAGOS\n",
    "column_names=[\"PDF\",\"RFC\", \"Entidad\", \"Tipo\", \"Fecha Presentacion\", \"Importe a Pagar\", \"Linea de Captura\", \"Num Operacion\", \"Vigencia\", \"Tipo de declaracion\", \"Fecha de Pago\",\"Concepto de Pago\", \"Path\"]\n",
    "df_Pagos = pd.DataFrame(exportDataPagos(Archivos_Pagos), columns=column_names)\n",
    "# df_Pagos\n",
    "\n",
    "# # ACUSE RECEPCION\n",
    "column_names = [\"PDF\",\"RFC\",\"Fecha_y_hora_presentacion\",\"Num_de_Operacion\",\"Periodo_de_declaracion\",\"Ejercicio\",\"total_a_pagar\",\"Vigente_hasta\",\"Linea_de_Captura\",\"Razon_Social\",\"Impuesto_a_favor\",\"Concepto de Pago\",\"Path\"]\n",
    "df_Declaracion = pd.DataFrame(exportDataDeclaracion(Archivos_Declaracion), columns=column_names)\n",
    "\n",
    "# # ACUSE Presentacion\n",
    "column_names = [\"PDF\",\"RFC\",\"Fecha_y_hora_presentacion\",\"Num_de_Operacion\",\"Periodo_de_declaracion\",\"Ejercicio\",\"total_a_pagar\",\"Vigente_hasta\",\"Linea_de_Captura\",\"Razon_Social\",\"Impuesto_a_favor\",\"Path\"]\n",
    "df_Acuse_Presentacion = pd.DataFrame(exportDataDeclaracion(Archivos_Acuse_Presentacion), columns=column_names)\n",
    "\n",
    "# # DIOT\n",
    "column_names = [\"PDF\",\"Usuario\", \"Archivo_Recibido\", \"tamanio\",\"Fecha_Recepcion\", \"Hora_Recepcion\", \"Folio\", \"Path\"]\n",
    "df_Diot = pd.DataFrame(exportDataDiot(Archivos_Diot), columns=column_names)\n",
    "\n",
    "\n",
    "# CONTANCIA\n",
    "column_names=[\"PDF\",\"RFC\", \"Razon_Social\", \"CURP\", \"Primer_Apellido\", \"Segundo_Apellido\", \"Nombre_Comercial\", \"Fecha_Operacion\", \"Estatus\", \"Regimenes\", \"Path\"]\n",
    "df_Constancia = pd.DataFrame(exportDataConstancia(Archivos_Constancia), columns=column_names)\n",
    "\n",
    "\n",
    "\n",
    "# Opinion de cumplimiento\n",
    "column_names=[\"PDF\",\"RFC\", \"Folio\", \"Path\"]\n",
    "df_Opinion_Cumplimiento =  pd.DataFrame(exportDataOpinionCumplimiento(Archivos_Opinion_Cumplimiento), columns=column_names)\n",
    "\n",
    "column_names=[\"Documentos sin clasificar\"]\n",
    "df_no_clasificados =  pd.DataFrame(Archivos_no_clasificados, columns=column_names)\n",
    "# df_no_clasificados\n",
    "\n",
    "# Export = pd.concat([df_Declaracion,\n",
    "#                     df_Acuse_Presentacion,\n",
    "#                     df_Diot,\n",
    "#                     df_Constancia,\n",
    "#                     df_Opinion_Cumplimiento,\n",
    "#                     df_Pagos\n",
    "#                     ])\n",
    "\n",
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Can't determine version for xlsxwriter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# import sys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# !{sys.executable} -m pip install xlsxwriter\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_Pagos\u001b[39m.\u001b[39;49mto_excel(\u001b[39m'\u001b[39;49m\u001b[39mdf_Pagos.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, index\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\core\\generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2361\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2363\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2364\u001b[0m     df,\n\u001b[0;32m   2365\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2372\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[0;32m   2373\u001b[0m )\n\u001b[1;32m-> 2374\u001b[0m formatter\u001b[39m.\u001b[39;49mwrite(\n\u001b[0;32m   2375\u001b[0m     excel_writer,\n\u001b[0;32m   2376\u001b[0m     sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[0;32m   2377\u001b[0m     startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[0;32m   2378\u001b[0m     startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[0;32m   2379\u001b[0m     freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[0;32m   2380\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m   2381\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2382\u001b[0m )\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\io\\formats\\excel.py:944\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    940\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    942\u001b[0m     \u001b[39m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    943\u001b[0m     \u001b[39m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 944\u001b[0m     writer \u001b[39m=\u001b[39m ExcelWriter(  \u001b[39m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    945\u001b[0m         writer, engine\u001b[39m=\u001b[39;49mengine, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1146\u001b[0m, in \u001b[0;36mExcelWriter.__new__\u001b[1;34m(cls, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     engine \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_option(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mio.excel.\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m.writer\u001b[39m\u001b[39m\"\u001b[39m, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1145\u001b[0m     \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1146\u001b[0m         engine \u001b[39m=\u001b[39m get_default_engine(ext, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwriter\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1147\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo engine for filetype: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\io\\excel\\_util.py:82\u001b[0m, in \u001b[0;36mget_default_engine\u001b[1;34m(ext, mode)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39massert\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mreader\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwriter\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwriter\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[39m# Prefer xlsxwriter over openpyxl if installed\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     xlsxwriter \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mxlsxwriter\u001b[39;49m\u001b[39m\"\u001b[39;49m, errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mwarn\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m xlsxwriter:\n\u001b[0;32m     84\u001b[0m         _default_writers[\u001b[39m\"\u001b[39m\u001b[39mxlsx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxlsxwriter\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\compat\\_optional.py:157\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    155\u001b[0m minimum_version \u001b[39m=\u001b[39m min_version \u001b[39mif\u001b[39;00m min_version \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m VERSIONS\u001b[39m.\u001b[39mget(parent)\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m minimum_version:\n\u001b[1;32m--> 157\u001b[0m     version \u001b[39m=\u001b[39m get_version(module_to_get)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m version \u001b[39mand\u001b[39;00m Version(version) \u001b[39m<\u001b[39m Version(minimum_version):\n\u001b[0;32m    159\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPandas requires version \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mminimum_version\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m or newer of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(version \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mversion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m currently installed).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         )\n",
      "File \u001b[1;32mf:\\Indicadores\\Program Files\\Anaconda\\envs\\Cuadras\\lib\\site-packages\\pandas\\compat\\_optional.py:83\u001b[0m, in \u001b[0;36mget_version\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msnappy\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     80\u001b[0m         \u001b[39m# snappy doesn't contain attributes to confirm it's version\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[39m# See https://github.com/andrix/python-snappy/pull/119\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt determine version for \u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m module\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpsycopg2\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     85\u001b[0m     \u001b[39m# psycopg2 appends \" (dt dec pq3 ext lo64)\" to it's version\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     version \u001b[39m=\u001b[39m version\u001b[39m.\u001b[39msplit()[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mImportError\u001b[0m: Can't determine version for xlsxwriter"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install xlsxwriter\n",
    "\n",
    "df_Pagos.to_excel('df_Pagos.xlsx', header=True, index=None)\n",
    "df_Declaracion.to_excel('./Dataframes/df_Declaracion.xlsx', header=True, index=None)\n",
    "df_Acuse_Presentacion.to_excel('./Dataframes/df_Acuse_Presentacion.xlsx', header=True, index=None)\n",
    "df_Diot.to_excel('./Dataframes/df_Diot.xlsx', header=True, index=None)\n",
    "df_Constancia.to_excel('./Dataframes/df_Constancia.xlsx', header=True, index=None)\n",
    "df_no_clasificados.to_excel('./Dataframes/df_no_Clasificados.xlsx', header=True, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuadras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e86978ce3236a4cc540f29f4170ac442f37169057576801bc3db58eb1c153e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
